import streamlit as st
from dotenv import load_dotenv
import os
import base64
import requests

load_dotenv()

# API Keys
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

st.set_page_config(page_title="Trá»£ lÃ½ AI tá»•ng há»£p", layout="wide")

# Sidebar
st.sidebar.title("ğŸ”§ TÃ­nh nÄƒng")
menu = st.sidebar.radio("Chá»n chá»©c nÄƒng", [
    "ğŸ¤– TrÃ² chuyá»‡n vá»›i trá»£ lÃ½ AI",
    "ğŸ—‚ Táº£i lÃªn tÃ i liá»‡u",
    "ğŸ’¾ LÆ°u phiÃªn trÃ² chuyá»‡n"
])

# Session state
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# === CÃ¡c hÃ m gá»i API ===
def get_deepseek_response(prompt):
    try:
        headers = {"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"}
        data = {"model": "deepseek-chat", "messages": [{"role": "user", "content": prompt}]}
        response = requests.post("https://api.deepseek.com/v1/chat/completions", headers=headers, json=data)
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[DeepSeek lá»—i]: {e}"

def get_gpt_response(prompt):
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
        data = {"model": "gpt-3.5-turbo", "messages": [{"role": "user", "content": prompt}]}
        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data)
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[GPT lá»—i]: {e}"

def get_gemini_response(prompt):
    try:
        headers = {"Content-Type": "application/json"}
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        response = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={GEMINI_API_KEY}",
            headers=headers, json=data
        )
        return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        return f"[Gemini lá»—i]: {e}"

# === Giao diá»‡n tá»«ng tab ===
if menu == "ğŸ¤– TrÃ² chuyá»‡n vá»›i trá»£ lÃ½ AI":
    st.title("ğŸ˜„ Trá»£ lÃ½ AI Ä‘a mÃ´ hÃ¬nh")
    selected_models = st.multiselect("Chá»n AI Ä‘á»ƒ xá»­ lÃ½ (thá»© tá»± Æ°u tiÃªn):", ["DeepSeek", "GPT", "Gemini"], default=["DeepSeek", "GPT", "Gemini"])
    prompt = st.text_input("Há»i gÃ¬ Ä‘Ã³ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u...")

    if prompt and selected_models:
        ai_results = {}
        final_answer = None

        for model in selected_models:
            if model == "DeepSeek":
                result = get_deepseek_response(prompt)
            elif model == "GPT":
                result = get_gpt_response(prompt)
            elif model == "Gemini":
                result = get_gemini_response(prompt)

            ai_results[model] = result

            if not result.startswith("[") and "lá»—i" not in result.lower():
                final_answer = result  # Ghi nháº­n pháº£n há»“i thÃ nh cÃ´ng cuá»‘i cÃ¹ng

        for model, result in ai_results.items():
            if result.startswith("["):
                st.error(f"âŒ {model} lá»—i: {result}")
            else:
                st.success(f"âœ… {model} pháº£n há»“i thÃ nh cÃ´ng.")

        st.markdown("### ğŸ’¡ Pháº£n há»“i tá»•ng há»£p")
        if final_answer:
            st.write(final_answer)
            st.session_state.chat_log.append(f"Báº¡n: {prompt}\nAI: {final_answer}")
        else:
            st.warning("Táº¥t cáº£ cÃ¡c AI Ä‘á»u gáº·p lá»—i. Vui lÃ²ng kiá»ƒm tra API key hoáº·c thá»­ láº¡i sau.")

elif menu == "ğŸ—‚ Táº£i lÃªn tÃ i liá»‡u":
    st.title("ğŸ“„ Táº£i lÃªn tÃ i liá»‡u (PDF, DOCX, TXT)")
    uploaded_files = st.file_uploader("KÃ©o tháº£ hoáº·c chá»n nhiá»u tá»‡p", type=["pdf", "docx", "txt"], accept_multiple_files=True)
    if uploaded_files:
        for file in uploaded_files:
            st.success(f"ÄÃ£ táº£i lÃªn: {file.name}")
    else:
        st.info("ChÆ°a cÃ³ tá»‡p nÃ o Ä‘Æ°á»£c táº£i lÃªn.")

elif menu == "ğŸ’¾ LÆ°u phiÃªn trÃ² chuyá»‡n":
    st.title("ğŸ’¾ Xuáº¥t toÃ n bá»™ trÃ² chuyá»‡n")
    if st.session_state.chat_log:
        chat_text = "\n\n".join(st.session_state.chat_log)
        b64 = base64.b64encode(chat_text.encode()).decode()
        href = f'<a href="data:file/txt;base64,{b64}" download="chat_log.txt">ğŸ“¥ Táº£i vá» file chat_log.txt</a>'
        st.markdown(href, unsafe_allow_html=True)
    else:
        st.info("ChÆ°a cÃ³ ná»™i dung trÃ² chuyá»‡n Ä‘á»ƒ lÆ°u.")
