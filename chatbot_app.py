import streamlit as st
from dotenv import load_dotenv
import os
import requests

load_dotenv()

st.set_page_config(page_title="Trá»£ lÃ½ AI tá»•ng há»£p", layout="wide")

# Sidebar
st.sidebar.title("ğŸ”§ TÃ­nh nÄƒng")
menu = st.sidebar.radio("Chá»n chá»©c nÄƒng", [
    "ğŸ’¬ TrÃ² chuyá»‡n vá»›i trá»£ lÃ½ AI",
    "ğŸ—‚ Táº£i lÃªn tÃ i liá»‡u",
    "ğŸ’¾ LÆ°u phiÃªn trÃ² chuyá»‡n"
])

# Session state
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

if menu == "ğŸ’¬ TrÃ² chuyá»‡n vá»›i trá»£ lÃ½ AI":
    st.title("ğŸ¤– Trá»£ lÃ½ AI Ä‘a mÃ´ hÃ¬nh")

    ai_options = ["DeepSeek", "GPT", "Gemini"]
    selected_ais = st.multiselect("Chá»n AI Ä‘á»ƒ xá»­ lÃ½ tuáº§n tá»± (thá»© tá»± quan trá»ng):", ai_options, default=["DeepSeek", "GPT", "Gemini"])
    user_input = st.text_input("Há»i gÃ¬ Ä‘Ã³ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§uâ€¦")

    if user_input:
        response_text = user_input

        for ai in selected_ais:
            if ai == "DeepSeek":
                try:
                    deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
                    res = requests.post(
                        "https://api.deepseek.com/chat/completions",
                        headers={"Authorization": f"Bearer {deepseek_api_key}"},
                        json={
                            "model": "deepseek-chat",
                            "messages": [{"role": "user", "content": response_text}]
                        }
                    )
                    response_text = res.json()["choices"][0]["message"]["content"]
                except Exception as e:
                    st.error(f"âŒ DeepSeek lá»—i: {e}")

            elif ai == "GPT":
                try:
                    openai_api_key = os.getenv("OPENAI_API_KEY")
                    res = requests.post(
                        "https://api.openai.com/v1/chat/completions",
                        headers={"Authorization": f"Bearer {openai_api_key}"},
                        json={
                            "model": "gpt-3.5-turbo",
                            "messages": [{"role": "user", "content": response_text}]
                        }
                    )
                    response_text = res.json()["choices"][0]["message"]["content"]
                except Exception as e:
                    st.error(f"âŒ GPT lá»—i: {e}")

            elif ai == "Gemini":
                try:
                    gemini_api_key = os.getenv("GEMINI_API_KEY")
                    res = requests.post(
                        f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={gemini_api_key}",
                        json={"contents": [{"parts": [{"text": response_text}]}]}
                    )
                    response_text = res.json()["candidates"][0]["content"]["parts"][0]["text"]
                except Exception as e:
                    st.error(f"âŒ Gemini lá»—i: {e}")

        st.subheader("ğŸ’¡ Pháº£n há»“i tá»•ng há»£p")
        st.write(response_text)
        st.session_state.chat_log.append(f"ğŸ§‘â€ğŸ’» {user_input}\nğŸ¤– {response_text}")

elif menu == "ğŸ—‚ Táº£i lÃªn tÃ i liá»‡u":
    st.title("ğŸ“„ Táº£i lÃªn tÃ i liá»‡u")
    uploaded_files = st.file_uploader("KÃ©o tháº£ hoáº·c chá»n nhiá»u tá»‡p", type=["pdf", "docx", "txt"], accept_multiple_files=True)
    if uploaded_files:
        for file in uploaded_files:
            st.success(f"ÄÃ£ táº£i lÃªn: {file.name}")
    else:
        st.info("ChÆ°a cÃ³ tá»‡p nÃ o Ä‘Æ°á»£c táº£i lÃªn.")

elif menu == "ğŸ’¾ LÆ°u phiÃªn trÃ² chuyá»‡n":
    st.title("ğŸ’¾ Xuáº¥t toÃ n bá»™ trÃ² chuyá»‡n")
    if st.session_state.chat_log:
        chat_text = "\n\n".join(st.session_state.chat_log)
        b64 = base64.b64encode(chat_text.encode()).decode()
        href = f'<a href="data:file/txt;base64,{b64}" download="chat_log.txt">ğŸ“¥ Táº£i vá» file chat_log.txt</a>'
        st.markdown(href, unsafe_allow_html=True)
    else:
        st.info("ChÆ°a cÃ³ ná»™i dung trÃ² chuyá»‡n Ä‘á»ƒ lÆ°u.")
